{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchaudio\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "import tqdm as notebook_tqdm\n",
    "import wandb\n",
    "import kagglehub\n",
    "import os\n",
    "from kaggle_secrets import UserSecretsClient\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\") # "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LCNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LCNN model\n",
    "\n",
    "import torchaudio\n",
    "from torch.utils.data import Dataset\n",
    "import os\n",
    "from torchaudio import transforms as T\n",
    "from torch.nn import Sequential\n",
    "\n",
    "class mfm(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, padding=1, type=1):\n",
    "        super(mfm, self).__init__()\n",
    "        self.out_channels = out_channels\n",
    "        if type == 1:\n",
    "            self.filter = nn.Conv2d(in_channels, 2*out_channels, kernel_size=kernel_size, stride=stride, padding=padding)\n",
    "        else:\n",
    "            self.filter = nn.Linear(in_channels, 2*out_channels)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.filter(x)\n",
    "        out = torch.split(x, self.out_channels, 1)\n",
    "        return torch.maximum(out[0], out[1])\n",
    "\n",
    "\n",
    "class LCNN(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            mfm(1, 32, 5, 1, 2), # 2\n",
    "\n",
    "            nn.MaxPool2d(2, 2),\n",
    "\n",
    "            mfm(32, 32, 1, 1, 0), # 5\n",
    "            nn.BatchNorm2d(32),\n",
    "            mfm(32, 48), # 8\n",
    "\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.BatchNorm2d(48),\n",
    "\n",
    "            mfm(48, 48, 1, 1, 0), # 12\n",
    "            nn.BatchNorm2d(48),\n",
    "            mfm(48, 64), # 15\n",
    "\n",
    "            nn.MaxPool2d(2, 2),\n",
    "\n",
    "            mfm(64, 64, 1, 1, 0), # 18\n",
    "            nn.BatchNorm2d(64),\n",
    "            mfm(64, 32), # 21\n",
    "            nn.BatchNorm2d(32),\n",
    "            mfm(32, 32, 1, 1, 0), # 24\n",
    "            nn.BatchNorm2d(32),\n",
    "            mfm(32, 32), # 27\n",
    "\n",
    "            nn.MaxPool2d(2, 2)\n",
    "        )\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            mfm(32 * 53 * 37, 80, type=0),  # FC-29 + MFM-30\n",
    "            nn.BatchNorm1d(80),\n",
    "            nn.Dropout(p=0.3),\n",
    "            nn.Linear(80, 2)  # FC-32\n",
    "        )\n",
    "        \n",
    "        self._inilialize_weights()\n",
    "    \n",
    "    def _inilialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, (nn.Conv2d, nn.Linear)):\n",
    "                nn.init.kaiming_normal_(m.weight, mode=\"fan_out\", nonlinearity=\"relu\")\n",
    "                if m.bias is not None:\n",
    "                    nn.init.zeros_(m.bias)\n",
    "            elif isinstance(m, (nn.BatchNorm2d, nn.BatchNorm1d)):\n",
    "                nn.init.ones_(m.weight)\n",
    "                nn.init.zeros_(m.bias)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset v2\n",
    "\n",
    "import os\n",
    "import logging\n",
    "import random\n",
    "from typing import List\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import torchaudio\n",
    "import torchaudio.transforms as T\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def get_index_from_path(path_of_dir : str, path_of_protocol : str) -> list[dict]:\n",
    "    _index = list()\n",
    "    with open(path_of_protocol, 'r') as f:\n",
    "        for line in f:\n",
    "            protocol = dict()\n",
    "            parts = line.strip().split()\n",
    "            filename = os.path.join(path_of_dir, parts[1] + '.flac')\n",
    "            label = 1 if parts[-1] == 'bonafide' else 0\n",
    "            protocol[\"path\"] = filename\n",
    "            protocol[\"label\"] = label\n",
    "            _index.append(protocol)\n",
    "    return _index\n",
    "\n",
    "\n",
    "class BaseDataset(Dataset):\n",
    "\n",
    "    def __init__(\n",
    "        self, index, limit=None, shuffle_index=False, instance_transforms=None\n",
    "    ):\n",
    "\n",
    "        self._assert_index_is_valid(index)\n",
    "\n",
    "        index = self._shuffle_and_limit_index(index, limit, shuffle_index)\n",
    "        self._index: List[dict] = index\n",
    "\n",
    "        self.instance_transforms = instance_transforms\n",
    "        self.max_frames = 600\n",
    "\n",
    "        self.fft_transform = T.Spectrogram(\n",
    "            n_fft=1724,\n",
    "            hop_length=130,\n",
    "            win_length=1724,\n",
    "            window_fn=torch.blackman_window,\n",
    "            power=2,\n",
    "            center=False\n",
    "        )\n",
    "        self.db_transform = T.AmplitudeToDB(stype='power')\n",
    "\n",
    "    def __getitem__(self, ind):\n",
    "        \"\"\"\n",
    "        Get element from the index, preprocess it, and combine it\n",
    "        into a dict.\n",
    "\n",
    "        Notice that the choice of key names is defined by the template user.\n",
    "        However, they should be consistent across dataset getitem, collate_fn,\n",
    "        loss_function forward method, and model forward method.\n",
    "\n",
    "        Args:\n",
    "            ind (int): index in the self.index list.\n",
    "        Returns:\n",
    "            instance_data (dict): dict, containing instance\n",
    "                (a single dataset element).\n",
    "        \"\"\"\n",
    "        data_dict = self._index[ind]\n",
    "        data_path = data_dict[\"path\"]\n",
    "        waveform, sr = self._load_object(data_path)\n",
    "        data_label = data_dict[\"label\"]\n",
    "        log_spectrogram = self.preprocess_data(waveform)\n",
    "\n",
    "        return log_spectrogram, data_label\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Get length of the dataset (length of the index).\n",
    "        \"\"\"\n",
    "        return len(self._index)\n",
    "\n",
    "    def _load_object(self, path):\n",
    "        \"\"\"\n",
    "        Load object from disk.\n",
    "\n",
    "        Args:\n",
    "            path (str): path to the object.\n",
    "        Returns:\n",
    "            data_object (Tensor):\n",
    "        \"\"\"\n",
    "        wave, sr = torchaudio.load(path)\n",
    "        return wave, sr\n",
    "\n",
    "    def preprocess_data(self, waveform):\n",
    "        \"\"\"\n",
    "        Preprocess data with instance transforms.\n",
    "\n",
    "        Each tensor in a dict undergoes its own transform defined by the key.\n",
    "\n",
    "        Args:\n",
    "            instance_data (dict): dict, containing instance\n",
    "                (a single dataset element).\n",
    "        Returns:\n",
    "            instance_data (Spectogram): Spectogram, containing waveform\n",
    "                (a single dataset element) (possibly transformed via\n",
    "                instance transform).\n",
    "        \"\"\"\n",
    "        power_spectrum = self.fft_transform(waveform)\n",
    "        log_spectrogram = self.db_transform(power_spectrum).squeeze(0)\n",
    "\n",
    "        num_frames = log_spectrogram.shape[1]\n",
    "        if num_frames < self.max_frames:\n",
    "            pad_amount = self.max_frames - num_frames\n",
    "            log_spectrogram = F.pad(\n",
    "                log_spectrogram, \n",
    "                (0, pad_amount), \n",
    "                mode='constant', \n",
    "                value=-80\n",
    "            )\n",
    "        else:\n",
    "            log_spectrogram = log_spectrogram[:, :self.max_frames]\n",
    "        \n",
    "        return log_spectrogram.unsqueeze(0)\n",
    "\n",
    "    @staticmethod\n",
    "    def _filter_records_from_dataset(\n",
    "        index: list,\n",
    "    ) -> list:\n",
    "        \"\"\"\n",
    "        Filter some of the elements from the dataset depending on\n",
    "        some condition.\n",
    "\n",
    "        This is not used in the example. The method should be called in\n",
    "        the __init__ before shuffling and limiting.\n",
    "\n",
    "        Args:\n",
    "            index (list[dict]): list, containing dict for each element of\n",
    "                the dataset. The dict has required metadata information,\n",
    "                such as label and object path.\n",
    "        Returns:\n",
    "            index (list[dict]): list, containing dict for each element of\n",
    "                the dataset that satisfied the condition. The dict has\n",
    "                required metadata information, such as label and object path.\n",
    "        \"\"\"\n",
    "        # Filter logic\n",
    "        pass\n",
    "\n",
    "    @staticmethod\n",
    "    def _assert_index_is_valid(index):\n",
    "        \"\"\"\n",
    "        Check the structure of the index and ensure it satisfies the desired\n",
    "        conditions.\n",
    "\n",
    "        Args:\n",
    "            index (list[dict]): list, containing dict for each element of\n",
    "                the dataset. The dict has required metadata information,\n",
    "                such as label and object path.\n",
    "        \"\"\"\n",
    "        for entry in index:\n",
    "            assert \"path\" in entry, (\n",
    "                \"Each dataset item should include field 'path'\" \" - path to audio file.\"\n",
    "            )\n",
    "            assert \"label\" in entry, (\n",
    "                \"Each dataset item should include field 'label'\"\n",
    "                \" - object ground-truth label.\"\n",
    "            )\n",
    "\n",
    "    @staticmethod\n",
    "    def _sort_index(index):\n",
    "        \"\"\"\n",
    "        Sort index via some rules.\n",
    "\n",
    "        This is not used in the example. The method should be called in\n",
    "        the __init__ before shuffling and limiting and after filtering.\n",
    "\n",
    "        Args:\n",
    "            index (list[dict]): list, containing dict for each element of\n",
    "                the dataset. The dict has required metadata information,\n",
    "                such as label and object path.\n",
    "        Returns:\n",
    "            index (list[dict]): sorted list, containing dict for each element\n",
    "                of the dataset. The dict has required metadata information,\n",
    "                such as label and object path.\n",
    "        \"\"\"\n",
    "        return sorted(index, key=lambda x: x[\"KEY_FOR_SORTING\"])\n",
    "\n",
    "    @staticmethod\n",
    "    def _shuffle_and_limit_index(index, limit, shuffle_index):\n",
    "        \"\"\"\n",
    "        Shuffle elements in index and limit the total number of elements.\n",
    "\n",
    "        Args:\n",
    "            index (list[dict]): list, containing dict for each element of\n",
    "                the dataset. The dict has required metadata information,\n",
    "                such as label and object path.\n",
    "            limit (int | None): if not None, limit the total number of elements\n",
    "                in the dataset to 'limit' elements.\n",
    "            shuffle_index (bool): if True, shuffle the index. Uses python\n",
    "                random package with seed 42.\n",
    "        \"\"\"\n",
    "        if shuffle_index:\n",
    "            random.seed(42)\n",
    "            random.shuffle(index)\n",
    "\n",
    "        if limit is not None:\n",
    "            index = index[:limit]\n",
    "        return index"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_det_curve(target_scores, nontarget_scores):\n",
    "\n",
    "    n_scores = target_scores.size + nontarget_scores.size\n",
    "    all_scores = np.concatenate((target_scores, nontarget_scores))\n",
    "    labels = np.concatenate(\n",
    "        (np.ones(target_scores.size), np.zeros(nontarget_scores.size)))\n",
    "\n",
    "    # Sort labels based on scores\n",
    "    indices = np.argsort(all_scores, kind='mergesort')\n",
    "    labels = labels[indices]\n",
    "\n",
    "    # Compute false rejection and false acceptance rates\n",
    "    tar_trial_sums = np.cumsum(labels)\n",
    "    nontarget_trial_sums = nontarget_scores.size - \\\n",
    "        (np.arange(1, n_scores + 1) - tar_trial_sums)\n",
    "\n",
    "    # false rejection rates\n",
    "    frr = np.concatenate(\n",
    "        (np.atleast_1d(0), tar_trial_sums / target_scores.size))\n",
    "    far = np.concatenate((np.atleast_1d(1), nontarget_trial_sums /\n",
    "                          nontarget_scores.size))  # false acceptance rates\n",
    "    # Thresholds are the sorted scores\n",
    "    thresholds = np.concatenate(\n",
    "        (np.atleast_1d(all_scores[indices[0]] - 0.001), all_scores[indices]))\n",
    "\n",
    "    return frr, far, thresholds\n",
    "\n",
    "\n",
    "def compute_eer(bonafide_scores, other_scores):\n",
    "    \"\"\" \n",
    "    Returns equal error rate (EER) and the corresponding threshold.\n",
    "    \"\"\"\n",
    "    frr, far, thresholds = compute_det_curve(bonafide_scores, other_scores)\n",
    "    abs_diffs = np.abs(frr - far)\n",
    "    min_index = np.argmin(abs_diffs)\n",
    "    eer = np.mean((frr[min_index], far[min_index]))\n",
    "    return eer, thresholds[min_index]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def train_one_epoch(model, dataloader, criterion, optimizer, scheduler, device):\n",
    "    # some layers may have different behavior for train and inference\n",
    "    # this is why it is important to set model to train mode during training\n",
    "    model.train()\n",
    "\n",
    "    avg_loss = 0\n",
    "    for batch_idx, (image, label) in tqdm(enumerate(dataloader), total=len(dataloader)):\n",
    "        # if we want to use GPU for model forward, we need to put inputs and desired outputs on device \n",
    "        image, label = image.to(device), label.to(device)\n",
    "\n",
    "        output = model(image) # calculate model output\n",
    "        loss = criterion(output, label) # calculate loss\n",
    "\n",
    "        loss.backward() # calculate gradients\n",
    "        optimizer.step() # update weights\n",
    "        optimizer.zero_grad() # zero gradients for the next step\n",
    "        # scheduler.step() # update learning rate\n",
    "\n",
    "        avg_loss += loss.item() # item to detach loss and get element on CPU\n",
    "        # item is used for tensors containing single scalar\n",
    "\n",
    "    # batch-idx + 1 == the total number of batches == len(dataloader)\n",
    "    avg_loss = avg_loss / (batch_idx + 1)\n",
    "    return avg_loss\n",
    "\n",
    "def evaluate(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "\n",
    "    avg_loss = 0\n",
    "    accuracy = 0\n",
    "    total_elements = 0\n",
    "    \n",
    "    # Для вычисления EER сохраняем все предсказанные оценки и метки\n",
    "    all_scores = []\n",
    "    all_labels = []\n",
    "\n",
    "    for batch_idx, (image, label) in enumerate(dataloader):\n",
    "        image, label = image.to(device), label.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output = model(image)\n",
    "            loss = criterion(output, label)\n",
    "\n",
    "        # Сохраняем оценки и метки для EER\n",
    "        scores = F.softmax(output, dim=1)[:, 1]  # Вероятности класса \"bonafide\" (предполагая, что класс 1 = bonafide)\n",
    "        all_scores.extend(scores.cpu().numpy())\n",
    "        all_labels.extend(label.cpu().numpy())\n",
    "\n",
    "        accuracy += (output.argmax(-1) == label).sum().item()\n",
    "        total_elements += output.shape[0]\n",
    "        avg_loss += loss.item()\n",
    "\n",
    "    avg_loss = avg_loss / (batch_idx + 1)\n",
    "    accuracy = 100 * accuracy / total_elements\n",
    "\n",
    "    # Вычисляем EER\n",
    "    all_scores = np.array(all_scores)\n",
    "    all_labels = np.array(all_labels)\n",
    "    \n",
    "    bonafide_scores = all_scores[all_labels == 1]  # Оценки для класса \"bonafide\"\n",
    "    other_scores = all_scores[all_labels == 0]     # Оценки для класса \"spoof\"\n",
    "    \n",
    "    eer, _ = compute_eer(bonafide_scores, other_scores)  # Используем функцию compute_eer из предыдущего примера\n",
    "\n",
    "    return avg_loss, accuracy, eer * 100\n",
    "\n",
    "def train(model, train_dataloader, val_dataloader, test_dataloader, criterion, optimizer, scheduler, device, n_epochs):\n",
    "\n",
    "    train_avg_losses = []\n",
    "    val_avg_losses = []\n",
    "    val_accuracy_list = []\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        print(f\"\\n--- Epoch {epoch+1}/{n_epochs} ---\")     \n",
    "        train_avg_loss = train_one_epoch(model, train_dataloader, criterion, optimizer, scheduler, device)\n",
    "        val_avg_loss, val_accuracy, err_val = evaluate(model, val_dataloader, criterion, device)\n",
    "        print(\"val_avg_loss:\", val_avg_loss)\n",
    "        print(\"val_accuracy:\", val_accuracy)\n",
    "        print(\"err_val:\", err_val)\n",
    "        scheduler.step()\n",
    "\n",
    "        wandb.log({\n",
    "            \"test_avg_loss\": val_avg_loss,\n",
    "            \"test_accuracy\": val_accuracy,\n",
    "            \"err\": err_val\n",
    "        }, step=8)\n",
    "    \n",
    "    test_avg_loss, test_accuracy, err_t = evaluate(model, test_dataloader, criterion, device)\n",
    "    print(\"test_avg_loss:\", test_avg_loss)\n",
    "    print(\"test_accuracy:\", test_accuracy)\n",
    "    print(\"test_val:\", err_t)\n",
    "    \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "NUM_EPOCHS = 8\n",
    "\n",
    "train_dataset = BaseDataset(get_index_from_path(\"/kaggle/input/asvpoof-2019-dataset/LA/LA/ASVspoof2019_LA_train/flac\", \n",
    "                            \"/kaggle/input/asvpoof-2019-dataset/LA/LA/ASVspoof2019_LA_cm_protocols/ASVspoof2019.LA.cm.train.trn.txt\"))\n",
    "val_dataset = BaseDataset(get_index_from_path(\"/kaggle/input/asvpoof-2019-dataset/LA/LA/ASVspoof2019_LA_eval/flac\", \n",
    "                          \"/kaggle/input/asvpoof-2019-dataset/LA/LA/ASVspoof2019_LA_cm_protocols/ASVspoof2019.LA.cm.eval.trl.txt\"))\n",
    "dev_dataset = BaseDataset(get_index_from_path(\"/kaggle/input/asvpoof-2019-dataset/LA/LA/ASVspoof2019_LA_dev/flac\", \n",
    "                          \"/kaggle/input/asvpoof-2019-dataset/LA/LA/ASVspoof2019_LA_cm_protocols/ASVspoof2019.LA.cm.dev.trl.txt\"))\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True, pin_memory=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=8, shuffle=False, pin_memory=True)\n",
    "dev_dataloader = DataLoader(dev_dataset, batch_size=8, shuffle=False, pin_memory=True)\n",
    "\n",
    "wandb.login(key=UserSecretsClient().get_secret(\"wandb\"))\n",
    "\n",
    "# Конфигурация\n",
    "config = {\n",
    "    \"learning_rate\": 3e-4,\n",
    "    \"batch_size\": 8,\n",
    "    \"epochs\": NUM_EPOCHS,\n",
    "    \"architecture\": \"LCNN\"\n",
    "}\n",
    "\n",
    "# Инициализация модели\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = LCNN()\n",
    "model.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=3e-4, weight_decay=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=NUM_EPOCHS, eta_min=1e-4)\n",
    "\n",
    "try:\n",
    "    with wandb.init(project=\"lcnn\", name=\"lcnn_run\", config=config, reinit=True):\n",
    "        train(model, train_dataloader, dev_dataloader, val_dataloader,\n",
    "              criterion, optimizer, scheduler, device, config[\"epochs\"])\n",
    "\n",
    "except Exception as e:\n",
    "    wandb.alert(title=\"Training Failed\", text=str(e))\n",
    "    raise\n",
    "finally:\n",
    "    wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
